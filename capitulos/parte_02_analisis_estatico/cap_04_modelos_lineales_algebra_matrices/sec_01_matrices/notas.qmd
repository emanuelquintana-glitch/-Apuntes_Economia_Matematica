---
title: "Capítulo 4-1: Modelos Lineales y Álgebra de Matrices"
subtitle: "Fundamentos de Economía Matemática"
author: 
  - name: "Emanuel Quintana Silva"
    affiliation: "Universidad Pedagógica y Tecnológica de Colombia (UPTC)"
    email: "emanuel.quintana@uptc.edu.co"
    orcid: "0009-0006-8419-2805"
date: "Diciembre 2025"
date-format: "MMMM YYYY"

format:
  html:
    theme: cosmo
    toc: true
    toc-depth: 4
    toc-location: left
    toc-title: "Contenido"
    number-sections: true
    number-depth: 4
    code-fold: show
    code-summary: "Mostrar código"
    code-tools: true
    code-copy: true
    code-overflow: wrap
    html-math-method: mathjax
    
  pdf:
    documentclass: book
    papersize: letter
    fontsize: 11pt
    geometry:
      - margin=1in
    number-sections: true
    toc: true
    toc-depth: 3
    colorlinks: true

execute:
  echo: true
  warning: false
  message: false
  cache: true

jupyter: python3
lang: es
---

```{python}
#| echo: false
#| output: false

import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import sympy as sp
from sympy import Matrix, symbols, latex, simplify, solve, det, eye
from IPython.display import display, Markdown, Latex
import warnings
warnings.filterwarnings('ignore')

plt.rcParams['figure.figsize'] = (10, 6)
plt.rcParams['font.size'] = 11
plt.rcParams['axes.grid'] = True
plt.rcParams['grid.alpha'] = 0.3

sp.init_printing(use_latex='mathjax')
```

::: {.callout-note icon=false}
## Información del Capítulo

**Basado en:** Chiang, A. C. & Wainwright, K. (2005). *Fundamental Methods of Mathematical Economics*. McGraw-Hill.

**Objetivo:** Introducir el álgebra de matrices como herramienta fundamental para el análisis de sistemas lineales en economía matemática, con aplicaciones a modelos de equilibrio de mercado, ingreso nacional y análisis insumo-producto.
:::

# Introducción al Álgebra Matricial

## El Desafío Dimensional en Economía

En economía matemática, el análisis de modelos con múltiples variables requiere metodologías que vayan más allá de las técnicas escalares tradicionales. El **álgebra de matrices** emerge como la herramienta fundamental para abordar el análisis estático o de equilibrio cuando el número de variables es grande.

::: {.callout-important}
## Necesidad del Álgebra Matricial

Cuando un modelo de mercado aumenta de uno a dos o más artículos, las fórmulas de eliminación de variables se vuelven rápidamente inmanejables. El álgebra de matrices proporciona una solución sistemática y elegante a este problema de complejidad.
:::

### Tres Ventajas Fundamentales

El álgebra de matrices ofrece ventajas cruciales para el análisis económico:

1. **Compacidad Notacional**: Proporciona una forma compacta de escribir sistemas de ecuaciones, incluso muy grandes
2. **Teoría de Existencia**: Permite probar la existencia de soluciones mediante la evaluación de determinantes
3. **Método Sistemático**: Suministra un procedimiento algorítmico para encontrar soluciones cuando existen

### Linealidad y Transformaciones

El álgebra de matrices se aplica específicamente a **sistemas de ecuaciones lineales**. Sin embargo, esta restricción no es limitante: modelos no lineales pueden transformarse mediante cambios de variables en relaciones lineales equivalentes.

**Ejemplo de Transformación:**
$$y = ax^b \quad \xrightarrow{\log} \quad \log y = \log a + b\log x$$

```{python}
#| label: fig-transformacion-log
#| fig-cap: "Transformación logarítmica de función no lineal a lineal"

fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(12, 5))

x = np.linspace(0.1, 10, 100)
a, b = 2, 1.5
y = a * x**b

# Gráfica original (no lineal)
ax1.plot(x, y, 'b-', linewidth=2, label=f'$y = {a}x^{{{b}}}$')
ax1.set_xlabel('x', fontsize=12)
ax1.set_ylabel('y', fontsize=12)
ax1.set_title('Función Original (No Lineal)', fontsize=14, fontweight='bold')
ax1.legend()
ax1.grid(True, alpha=0.3)

# Gráfica transformada (lineal)
log_x = np.log(x)
log_y = np.log(y)
ax2.plot(log_x, log_y, 'r-', linewidth=2, label=f'$\\log y = \\log {a} + {b}\\log x$')
ax2.set_xlabel('log(x)', fontsize=12)
ax2.set_ylabel('log(y)', fontsize=12)
ax2.set_title('Función Transformada (Lineal)', fontsize=14, fontweight='bold')
ax2.legend()
ax2.grid(True, alpha=0.3)

plt.tight_layout()
plt.show()
```

# Matrices como Arreglos Rectangulares

## Definición Formal

Una **matriz** se define como un **arreglo rectangular** de números, parámetros o variables. Los elementos individuales se identifican mediante subíndices dobles.

::: {.callout-tip}
## Definición: Matriz

Una matriz $\mathbf{A}$ de dimensión $m \times n$ es un arreglo rectangular de $m$ filas y $n$ columnas:

$$\mathbf{A} = \begin{bmatrix}
a_{11} & a_{12} & \cdots & a_{1n} \\
a_{21} & a_{22} & \cdots & a_{2n} \\
\vdots & \vdots & \ddots & \vdots \\
a_{m1} & a_{m2} & \cdots & a_{mn}
\end{bmatrix}$$

Donde $a_{ij}$ denota el elemento en la fila $i$ y columna $j$.
:::

```{python}
# Ejemplo de matriz
A = np.array([
    [6, 3, 1],
    [1, 4, -2],
    [4, -1, 5]
])

print("Matriz A (3×3):")
print(A)
print(f"\nDimensión: {A.shape[0]}×{A.shape[1]}")
print(f"Elemento a₂₃ = {A[1, 2]}")
```

## Representación de Sistemas Lineales

Un sistema de $m$ ecuaciones lineales en $n$ variables se puede escribir de manera compacta mediante la **notación matricial $\mathbf{Ax = d}$**.

Para el sistema general:
$$\begin{cases}
a_{11}x_1 + a_{12}x_2 + \cdots + a_{1n}x_n = d_1 \\
a_{21}x_1 + a_{22}x_2 + \cdots + a_{2n}x_n = d_2 \\
\vdots \\
a_{m1}x_1 + a_{m2}x_2 + \cdots + a_{mn}x_n = d_m
\end{cases}$$

La representación matricial es:
$$\begin{bmatrix}
a_{11} & a_{12} & \cdots & a_{1n} \\
a_{21} & a_{22} & \cdots & a_{2n} \\
\vdots & \vdots & \ddots & \vdots \\
a_{m1} & a_{m2} & \cdots & a_{mn}
\end{bmatrix}
\begin{bmatrix} x_1 \\ x_2 \\ \vdots \\ x_n \end{bmatrix}
=
\begin{bmatrix} d_1 \\ d_2 \\ \vdots \\ d_m \end{bmatrix}$$

Donde:
- $\mathbf{A}$: Matriz de coeficientes $(m \times n)$
- $\mathbf{x}$: Vector de variables $(n \times 1)$
- $\mathbf{d}$: Vector de términos constantes $(m \times 1)$

```{python}
# Sistema matricial ejemplo
A_sym = Matrix([[6, 3, 1], [1, 4, -2], [4, -1, 5]])
x_sym = Matrix([symbols('x_1'), symbols('x_2'), symbols('x_3')])
d_sym = Matrix([symbols('d_1'), symbols('d_2'), symbols('d_3')])

print("Sistema: Ax = d")
print("\nMatriz A:")
display(A_sym)
print("\nVector x:")
display(x_sym)
print("\nVector d:")
display(d_sym)
```

# Vectores como Matrices Especiales

## Tipos de Vectores

Un **vector** es una matriz que posee una única columna o un único renglón.

::: {.callout-tip}
## Clasificación Vectorial

**Vector Columna** ($m \times 1$):
$$\mathbf{x} = \begin{bmatrix} x_1 \\ x_2 \\ \vdots \\ x_m \end{bmatrix}$$

**Vector Renglón** ($1 \times n$):
$$\mathbf{x}' = \begin{bmatrix} x_1 & x_2 & \cdots & x_n \end{bmatrix}$$
:::

```{python}
# Vectores columna y renglón
v_columna = np.array([[3], [2], [1]])
v_renglon = np.array([[1, 4, 5]])

print("Vector columna (3×1):")
print(v_columna)
print(f"Dimensión: {v_columna.shape}")

print("\nVector renglón (1×3):")
print(v_renglon)
print(f"Dimensión: {v_renglon.shape}")
```

## Interpretación Geométrica

Todo vector con $n$ componentes puede interpretarse como una **$n$-tupla ordenada**, equivalente a un punto en el espacio euclidiano $\mathbb{R}^n$.

```{python}
#| label: fig-vectores-geometrico
#| fig-cap: "Interpretación geométrica de vectores en ℝ²"

fig = plt.figure(figsize=(10, 8))
ax = fig.add_subplot(111)

# Vectores
v1 = np.array([3, 2])
v2 = np.array([1, 4])
v_suma = v1 + v2

# Dibujar vectores
ax.quiver(0, 0, v1[0], v1[1], angles='xy', scale_units='xy', scale=1, 
          color='red', width=0.006, label=r'$\mathbf{v}_1 = (3, 2)$')
ax.quiver(0, 0, v2[0], v2[1], angles='xy', scale_units='xy', scale=1, 
          color='blue', width=0.006, label=r'$\mathbf{v}_2 = (1, 4)$')
ax.quiver(0, 0, v_suma[0], v_suma[1], angles='xy', scale_units='xy', scale=1, 
          color='green', width=0.008, label=r'$\mathbf{v}_1 + \mathbf{v}_2 = (4, 6)$')

# Configuración
ax.set_xlim(-0.5, 5)
ax.set_ylim(-0.5, 7)
ax.set_xlabel('$x_1$', fontsize=12)
ax.set_ylabel('$x_2$', fontsize=12)
ax.set_title('Vectores en $\mathbb{R}^2$', fontsize=14, fontweight='bold')
ax.axhline(y=0, color='k', linewidth=0.5)
ax.axvline(x=0, color='k', linewidth=0.5)
ax.grid(True, alpha=0.3)
ax.legend(fontsize=11)
ax.set_aspect('equal')

plt.tight_layout()
plt.show()
```

## Producto Escalar (Norma)

El **producto escalar** o **producto punto** de un vector consigo mismo define su norma (longitud euclidiana):

$$\|\mathbf{x}\| = \sqrt{\mathbf{x}'\mathbf{x}} = \sqrt{\sum_{i=1}^{n} x_i^2}$$

```{python}
# Norma de un vector
v = np.array([[3], [4]])
norma = np.linalg.norm(v)
producto_escalar = np.dot(v.T, v)[0,0]

print(f"Vector v: {v.T}")
print(f"Producto escalar v'v = {producto_escalar}")
print(f"Norma ||v|| = √{producto_escalar} = {norma:.4f}")
```

# Operaciones Fundamentales con Matrices

## Igualdad de Matrices

::: {.callout-tip}
## Definición: Igualdad Matricial

Dos matrices $\mathbf{A} = [a_{ij}]$ y $\mathbf{B} = [b_{ij}]$ son iguales si y solo si:

1. Poseen la misma dimensión: $m \times n$
2. Todos los elementos correspondientes son idénticos: $a_{ij} = b_{ij}$ para todo $i, j$
:::

## Suma y Resta de Matrices

**Condición de Conformabilidad:** Las matrices deben tener la **misma dimensión**.

$$\mathbf{C} = \mathbf{A} + \mathbf{B} \implies c_{ij} = a_{ij} + b_{ij}$$

**Propiedades:**
- **Conmutativa**: $\mathbf{A + B = B + A}$
- **Asociativa**: $\mathbf{(A + B) + C = A + (B + C)}$

```{python}
# Suma de matrices
A = np.array([[4, 9], [2, 1]])
B = np.array([[2, 0], [0, 7]])
C = A + B

print("Matriz A:")
print(A)
print("\nMatriz B:")
print(B)
print("\nMatriz C = A + B:")
print(C)
print("\n¿A + B = B + A?", np.array_equal(A + B, B + A))
```

## Multiplicación Escalar

Multiplicar una matriz por un escalar $\alpha$ implica multiplicar cada elemento:

$$\alpha\mathbf{A} = [\alpha a_{ij}]$$

**Propiedades:**
- $\alpha(\mathbf{A + B}) = \alpha\mathbf{A} + \alpha\mathbf{B}$ (Distributiva)
- $(\alpha + \beta)\mathbf{A} = \alpha\mathbf{A} + \beta\mathbf{A}$ (Distributiva)

```{python}
# Multiplicación escalar
A = np.array([[3, -1], [0, 5]])
alpha = 7
resultado = alpha * A

print(f"Matriz A:")
print(A)
print(f"\nEscalar α = {alpha}")
print(f"\nResultado {alpha}A:")
print(resultado)
```

# Multiplicación de Matrices

## Condición de Conformabilidad

::: {.callout-important}
## Regla Dimensional

El producto $\mathbf{AB}$ está definido si y solo si:

$$\mathbf{A}_{m \times n} \times \mathbf{B}_{n \times q} = \mathbf{C}_{m \times q}$$

El número de **columnas** de $\mathbf{A}$ debe ser igual al número de **filas** de $\mathbf{B}$.
:::

## Definición del Producto

Cada elemento $c_{ij}$ de la matriz producto se define como el **producto interior** de la fila $i$ de $\mathbf{A}$ con la columna $j$ de $\mathbf{B}$:

$$c_{ij} = \sum_{k=1}^{n} a_{ik}b_{kj} = a_{i1}b_{1j} + a_{i2}b_{2j} + \cdots + a_{in}b_{nj}$$

```{python}
# Multiplicación de matrices
A = np.array([[2, 3], [1, 4]])
B = np.array([[5, 1], [2, 3]])
C = np.dot(A, B)

print("Matriz A (2×2):")
print(A)
print("\nMatriz B (2×2):")
print(B)
print("\nMatriz C = AB:")
print(C)

# Verificación elemento por elemento
print(f"\nc₁₁ = {A[0,0]}·{B[0,0]} + {A[0,1]}·{B[1,0]} = {A[0,0]*B[0,0] + A[0,1]*B[1,0]}")
print(f"c₁₂ = {A[0,0]}·{B[0,1]} + {A[0,1]}·{B[1,1]} = {A[0,0]*B[0,1] + A[0,1]*B[1,1]}")
```

## Propiedades Algebraicas

::: {.callout-warning}
## No Conmutatividad

En general: $\mathbf{AB} \neq \mathbf{BA}$

El orden de los factores **sí altera** el producto. Esta es la diferencia más importante respecto al álgebra escalar.
:::

```{python}
# Demostración de no conmutatividad
A = np.array([[1, 2], [3, 4]])
B = np.array([[5, 6], [7, 8]])

AB = np.dot(A, B)
BA = np.dot(B, A)

print("AB:")
print(AB)
print("\nBA:")
print(BA)
print(f"\n¿AB = BA? {np.array_equal(AB, BA)}")
```

::: {.callout-tip}
## Propiedades Importantes

1. **Asociativa**: $(\mathbf{AB})\mathbf{C} = \mathbf{A}(\mathbf{BC}) = \mathbf{ABC}$
2. **Distributiva**: $\mathbf{A(B + C) = AB + AC}$ y $\mathbf{(A + B)C = AC + BC}$
3. **Transpuesta del producto**: $(\mathbf{AB})' = \mathbf{B}'\mathbf{A}'$ (orden inverso)
:::

# Multiplicación de Vectores

## Vector Columna × Vector Renglón (Producto Exterior)

**Producto Exterior** ($\mathbf{uv}'$): Genera una **matriz**

$$\mathbf{u}_{m \times 1} \times \mathbf{v}'_{1 \times n} = \mathbf{M}_{m \times n}$$

```{python}
# Producto exterior
u = np.array([[3], [2]])
v_t = np.array([[1, 4, 5]])

M = np.dot(u, v_t)

print("Vector u (columna):")
print(u)
print("\nVector v' (renglón):")
print(v_t)
print("\nProducto exterior uv':")
print(M)
```

## Vector Renglón × Vector Columna (Producto Interior)

**Producto Interior** ($\mathbf{u}'\mathbf{v}$): Genera un **escalar**

$$\mathbf{u}'_{1 \times n} \times \mathbf{v}_{n \times 1} = s_{1 \times 1}$$

$$\mathbf{u} \cdot \mathbf{v} = \sum_{i=1}^{n} u_iv_i$$

```{python}
# Producto interior (producto punto)
u_t = np.array([[3, 4]])
v = np.array([[9], [7]])

s = np.dot(u_t, v)

print("Vector u' (renglón):")
print(u_t)
print("\nVector v (columna):")
print(v)
print("\nProducto interior u'v:")
print(s)
print(f"\nCálculo: 3(9) + 4(7) = {3*9 + 4*7}")
```

## Aplicación Económica: Costo Total

```{python}
# Ejemplo: Costo total de compra
cantidades = np.array([[10, 5, 3]])  # Q' (renglón)
precios = np.array([[50], [100], [200]])  # P (columna)

costo_total = np.dot(cantidades, precios)[0, 0]

print("Cantidades Q' (unidades):")
print(cantidades)
print("\nPrecios P ($/unidad):")
print(precios)
print(f"\nCosto Total = Q'·P = ${costo_total:,.0f}")
```

# Matrices Especiales

## Matrices Cuadradas

Una matriz es **cuadrada** cuando tiene el mismo número de filas que de columnas ($m = n$).

**Propiedades especiales:**
- Solo las matrices cuadradas pueden tener inversa
- El determinante solo está definido para matrices cuadradas
- Las potencias de matrices solo están definidas para matrices cuadradas

### Diagonal Principal

Los elementos $a_{ii}$ donde $i = j$ forman la **diagonal principal**:

$$\text{diag}(\mathbf{A}) = \{a_{11}, a_{22}, \ldots, a_{nn}\}$$

### Traza

La **traza** de una matriz cuadrada es la suma de los elementos de su diagonal principal:

$$\text{tr}(\mathbf{A}) = \sum_{i=1}^{n} a_{ii}$$

```{python}
# Matriz cuadrada y sus propiedades
A = np.array([
    [5, 2, 1],
    [3, 7, 4],
    [2, 1, 9]
])

diagonal = np.diag(A)
traza = np.trace(A)

print("Matriz cuadrada A (3×3):")
print(A)
print(f"\nDiagonal principal: {diagonal}")
print(f"Traza tr(A) = {traza}")
```

## Matriz Diagonal

Una matriz cuadrada donde todos los elementos fuera de la diagonal principal son cero:

$$\mathbf{D} = \begin{bmatrix}
d_1 & 0 & \cdots & 0 \\
0 & d_2 & \cdots & 0 \\
\vdots & \vdots & \ddots & \vdots \\
0 & 0 & \cdots & d_n
\end{bmatrix}$$

**Propiedades:**
- Producto de matrices diagonales es diagonal
- La potencia n-ésima: $\mathbf{D}^n = \text{diag}(d_1^n, d_2^n, \ldots, d_n^n)$

```{python}
# Matriz diagonal
D = np.diag([3, -1, 5])

print("Matriz diagonal D:")
print(D)

# Potencias de matriz diagonal
D_cuadrada = np.linalg.matrix_power(D, 2)
D_cubica = np.linalg.matrix_power(D, 3)

print("\nD²:")
print(D_cuadrada)
print("\nD³:")
print(D_cubica)
```

## Matriz Identidad

La **matriz identidad** $\mathbf{I}$ es una matriz diagonal con todos los elementos diagonales iguales a 1:

$$\mathbf{I}_n = \begin{bmatrix}
1 & 0 & \cdots & 0 \\
0 & 1 & \cdots & 0 \\
\vdots & \vdots & \ddots & \vdots \\
0 & 0 & \cdots & 1
\end{bmatrix}$$

**Propiedad fundamental:**
$$\mathbf{I}_m\mathbf{A} = \mathbf{A}\mathbf{I}_n = \mathbf{A}$$

```{python}
# Matriz identidad
I3 = np.eye(3)
A = np.array([[2, 3, 1], [4, 1, 5], [2, 0, 3]])

IA = np.dot(I3, A)
AI = np.dot(A, I3)

print("Matriz Identidad I₃:")
print(I3)
print("\n¿I·A = A?", np.allclose(IA, A))
print("¿A·I = A?", np.allclose(AI, A))
```

## Matriz Nula

La **matriz nula** $\mathbf{0}$ tiene todos sus elementos iguales a cero:

$$\mathbf{0}_{m \times n} = \begin{bmatrix}
0 & 0 & \cdots & 0 \\
0 & 0 & \cdots & 0 \\
\vdots & \vdots & \ddots & \vdots \\
0 & 0 & \cdots & 0
\end{bmatrix}$$

**Propiedades:**
- $\mathbf{A} + \mathbf{0} = \mathbf{A}$
- $\mathbf{A} \cdot \mathbf{0} = \mathbf{0}$

# Transpuesta de una Matriz

## Definición

La **transpuesta** $\mathbf{A}'$ (o $\mathbf{A}^T$) se obtiene intercambiando filas por columnas:

$$\text{Si } \mathbf{A} = [a_{ij}]_{m \times n} \implies \mathbf{A}' = [a_{ji}]_{n \times m}$$

```{python}
# Transpuesta
A = np.array([[1, 2, 3], [4, 5, 6]])
A_T = A.T

print("Matriz A (2×3):")
print(A)
print("\nTranspuesta A' (3×2):")
print(A_T)
```

## Propiedades de la Transpuesta

::: {.callout-tip}
## Propiedades Fundamentales

1. $(\mathbf{A}')' = \mathbf{A}$
2. $(\mathbf{A} + \mathbf{B})' = \mathbf{A}' + \mathbf{B}'$
3. $(\alpha\mathbf{A})' = \alpha\mathbf{A}'$
4. $(\mathbf{AB})' = \mathbf{B}'\mathbf{A}'$ (orden inverso)
5. $(\mathbf{A}^{-1})' = (\mathbf{A}')^{-1}$
:::

```{python}
# Verificación de (AB)' = B'A'
A = np.array([[1, 2], [3, 4]])
B = np.array([[5, 6], [7, 8]])

AB = np.dot(A, B)
AB_T = AB.T
B_T_A_T = np.dot(B.T, A.T)

print("¿(AB)' = B'A'?", np.allclose(AB_T, B_T_A_T))
```

## Matrices Simétricas y Antisimétricas

### Matriz Simétrica

Una matriz cuadrada es **simétrica** si $\mathbf{A} = \mathbf{A}'$

$$a_{ij} = a_{ji} \quad \forall i, j$$

```{python}
# Matriz simétrica
A_sim = np.array([[5, 2, 1], [2, 3, 4], [1, 4, 6]])

print("Matriz simétrica A:")
print(A_sim)
print(f"\n¿Es simétrica? {np.allclose(A_sim, A_sim.T)}")
```

### Matriz Antisimétrica

Una matriz cuadrada es **antisimétrica** si $\mathbf{A} = -\mathbf{A}'$

$$a_{ij} = -a_{ji} \quad \forall i, j$$

```{python}
# Matriz antisimétrica
A_antisim = np.array([[0, 2, -3], [-2, 0, 5], [3, -5, 0]])

print("Matriz antisimétrica A:")
print(A_antisim)
print(f"\n¿Es antisimétrica? {np.allclose(A_antisim, -A_antisim.T)}")
```

# Determinantes

## Definición y Propiedades

El **determinante** es una función escalar que asigna a cada matriz cuadrada $\mathbf{A}$ un número real, denotado $|\mathbf{A}|$ o $\det(\mathbf{A})$.

### Determinante 2×2

$$|\mathbf{A}| = \begin{vmatrix}
a_{11} & a_{12} \\
a_{21} & a_{22}
\end{vmatrix}
= a_{11}a_{22} - a_{12}a_{21}$$

